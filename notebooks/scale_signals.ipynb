{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import torch as th\n",
    "import SharedArray as sa\n",
    "import os\n",
    "import nutils\n",
    "import common as cm\n",
    "import cupy as cp\n",
    "from tqdm import tqdm\n",
    "from numba import prange\n",
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = cm.SELECTED_CODES\n",
    "def get_data(code):\n",
    "    x = pd.read_csv(\n",
    "        f\"/home/ywang/workspace/alphagen/t0/stkCode_{code}.csv\", header=None\n",
    "    )\n",
    "    y = sa.attach(f\"label_{code}\")\n",
    "    z = sa.attach(f\"timestamp_{code}\")\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:53:22<00:00, 104.02s/it] \n"
     ]
    }
   ],
   "source": [
    "for code in tqdm(codes):\n",
    "    x, y, ts = get_data(code)\n",
    "    with cp.cuda.Device(1):  # Use GPU 1\n",
    "        # Convert to CuPy array and ensure float32\n",
    "        x_cp = cp.array(x, dtype=cp.float32)\n",
    "        \n",
    "        # Replace NaNs with 0\n",
    "        x_cp = cp.nan_to_num(x_cp, nan=0.0)\n",
    "        \n",
    "        # Standardize using CuPy\n",
    "        mean = cp.mean(x_cp, axis=0)\n",
    "        std = cp.std(x_cp, axis=0)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        std[std == 0] = 1.0\n",
    "        \n",
    "        x_cp = (x_cp - mean) / std\n",
    "        \n",
    "        # Convert back to NumPy array\n",
    "        x_np = cp.asnumpy(x_cp)\n",
    "    \n",
    "    # Save the standardized data\n",
    "    np.save(f\"/mnt/nas/data/WY/factors/{code}.npy\", x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(f\"/mnt/nas/data/WY/factors/{code}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "    # from sklearn.preprocessing import StandardScaler\n",
    "    # for code in tqdm(codes):\n",
    "    #     x, y, ts = get_data(code)\n",
    "    #     x = np.nan_to_num(x, 0, 0, 0).astype(np.float32)\n",
    "    #     scaler = StandardScaler()\n",
    "    #     x = scaler.fit_transform(x)\n",
    "    #     np.save(f\"/mnt/nas/data/WY/factors/{code}.npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]RuntimeWarning: overflow encountered in cast\n",
      "  1%|          | 1/100 [02:54<4:47:56, 174.51s/it]RuntimeWarning: overflow encountered in cast\n",
      "  2%|▏         | 2/100 [06:21<5:16:20, 193.68s/it]RuntimeWarning: overflow encountered in cast\n",
      "  3%|▎         | 3/100 [09:13<4:56:47, 183.58s/it]RuntimeWarning: overflow encountered in cast\n",
      "  4%|▍         | 4/100 [11:55<4:40:35, 175.37s/it]RuntimeWarning: overflow encountered in cast\n",
      "  5%|▌         | 5/100 [13:14<3:42:11, 140.33s/it]RuntimeWarning: overflow encountered in cast\n"
     ]
    }
   ],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def global_standardize(x):\n",
    "    n, m = x.shape\n",
    "    \n",
    "    # Calculate global mean and std for each column manually\n",
    "    means = np.zeros(m)\n",
    "    stds = np.zeros(m)\n",
    "    \n",
    "    for j in range(m):\n",
    "        column = x[:, j]\n",
    "        means[j] = np.mean(column)\n",
    "        stds[j] = np.std(column)\n",
    "    \n",
    "    # Initialize the standardized array\n",
    "    x_standardized = np.zeros_like(x)\n",
    "    \n",
    "    # Standardize the data\n",
    "    for i in prange(n):\n",
    "        for j in range(m):\n",
    "            if stds[j] > 0:\n",
    "                x_standardized[i, j] = (x[i, j] - means[j]) / stds[j]\n",
    "            else:\n",
    "                x_standardized[i, j] = 0\n",
    "\n",
    "    return x_standardized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@nb.njit(parallel=True)\n",
    "def standardize_by_day_numba(x, ts):\n",
    "    n, m = x.shape\n",
    "    unique_days = np.unique(ts)\n",
    "    x_standardized = np.zeros_like(x)\n",
    "\n",
    "    for i in prange(len(unique_days)):\n",
    "        day = unique_days[i]\n",
    "        mask = ts == day\n",
    "        indices = np.where(mask)[0]\n",
    "        x_day = x[indices]\n",
    "        \n",
    "        # Manually calculate mean and std for each column\n",
    "        means = np.zeros(m)\n",
    "        stds = np.zeros(m)\n",
    "        for j in range(m):\n",
    "            column = x_day[:, j]\n",
    "            means[j] = np.mean(column)\n",
    "            stds[j] = np.std(column)\n",
    "        \n",
    "        # Standardize\n",
    "        for k in indices:\n",
    "            for j in range(m):\n",
    "                if stds[j] > 0:\n",
    "                    x_standardized[k, j] = (x[k, j] - means[j]) / stds[j]\n",
    "                else:\n",
    "                    x_standardized[k, j] = 0\n",
    "\n",
    "    return x_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]RuntimeWarning: overflow encountered in cast\n",
      "  1%|          | 1/100 [02:57<4:52:24, 177.21s/it]"
     ]
    }
   ],
   "source": [
    "for code in tqdm(codes):\n",
    "    x, y, ts = get_data(code)\n",
    "    x = np.nan_to_num(x, 0, 0, 0).astype(np.float32)\n",
    "    x_standardized = standardize_by_day_numba(x, ts)\n",
    "    # x_standardized_cpu = cp.asnumpy(x_standardized)\n",
    "    np.save(f\"/mnt/nas/data/WY/factors/{code}.npy\", x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_by_day_on_gpu(x, ts, device_id=0):\n",
    "    with cp.cuda.Device(device_id):\n",
    "        # 将 numpy 数组转换为 cupy 数组\n",
    "        x_cp = cp.array(x)\n",
    "        ts_cp = cp.array(ts)\n",
    "        n, m = x_cp.shape\n",
    "\n",
    "        # 获取所有唯一的天数\n",
    "        unique_days = cp.unique(ts_cp)\n",
    "\n",
    "        # 初始化标准化后的数组\n",
    "        x_standardized = cp.zeros_like(x_cp)\n",
    "\n",
    "        # 按天标准化\n",
    "        for day in unique_days:\n",
    "            mask = ts_cp == day\n",
    "            x_day = x_cp[mask]\n",
    "            # 计算每一列的均值和标准差\n",
    "            mean = cp.mean(x_day, axis=0)\n",
    "            std = cp.std(x_day, axis=0)\n",
    "            # 标准化\n",
    "            x_standardized[mask] = (x_day - mean) / std\n",
    "\n",
    "        # 将标准化后的数据从 GPU 转回 CPU 并转换为 numpy 数组\n",
    "        return cp.asnumpy(x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in tqdm(codes):\n",
    "    x, y, ts = get_data(code)\n",
    "    x = np.nan_to_num(x, 0, 0, 0).astype(np.float32)\n",
    "    x_standardized = standardize_by_day_on_gpu(x, ts)\n",
    "    x_standardized_cpu = cp.asnumpy(x_standardized)\n",
    "    np.save(f\"/mnt/nas/data/WY/factor/{code}.npy\", x_standardized_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
